{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare DALI for fine-tune task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Vocals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DALI as dali_code\n",
    "import os\n",
    "import torch\n",
    "from lsync.voice_extractor import VoiceExtractor\n",
    "from lsync.config import ORIGINAL_SR, TARGET_SR\n",
    "from lsync.util import save_audio, save_audio_file\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "path_audio = os.path.abspath('dataset/DALI/audio')\n",
    "path_vocals = os.path.abspath(\"dataset/DALI/processed_audio\")\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted = set([os.path.splitext(x)[0] for x in os.listdir(path_vocals)])\n",
    "ve = VoiceExtractor()\n",
    "\n",
    "for fname in tqdm(os.listdir(path_audio)):\n",
    "    try:\n",
    "        audio_name, ext = os.path.splitext(fname)\n",
    "        if ext != '.mp3' or audio_name in converted:\n",
    "            continue\n",
    "        file_path = os.path.join(path_audio, fname)\n",
    "        vocals = ve.extract_voice(file_path, post_process=True)\n",
    "        save_audio(vocals, audio_name, sr=TARGET_SR, out_path=path_vocals)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make Speech Recognition Dataset for Fine-tune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load DALI annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DALI as dali_code\n",
    "import os\n",
    "from lsync.util import save_audio_file\n",
    "import pandas as pd\n",
    "import librosa\n",
    "\n",
    "dali_data_path = os.path.abspath('dataset/DALI/v1')\n",
    "path_audio = os.path.abspath('dataset/DALI/audio')\n",
    "dali_data = dali_code.get_the_DALI_dataset(dali_data_path, skip=[], keep=[])\n",
    "dali_info = dali_code.get_info(dali_data_path + '/info/DALI_DATA_INFO.gz')\n",
    "path_segments = os.path.abspath(\"dataset/DALI/segmented_audio\")\n",
    "csv_path = os.path.abspath('dali_lines.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make lyrics line level dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_songs = [os.path.splitext(x)[0] for x in os.listdir(path_vocals)]\n",
    "\n",
    "def extract_audio_segment(audio, time_seg, save_path, sr = TARGET_SR):\n",
    "    start_t, end_t = time_seg\n",
    "    start_idx, end_idx = int(start_t * sr), int(end_t * sr)\n",
    "    segment = audio[start_idx:end_idx]\n",
    "    save_audio_file(segment, save_path, sr=sr)\n",
    "    return segment\n",
    "\n",
    "def get_segment_fname(id: str, segment_index: int):\n",
    "    return f\"{id}_{segment_index}\"\n",
    "\n",
    "def make_dataset():\n",
    "    data_list = []\n",
    "    for id in tqdm(processed_songs):\n",
    "        # Get vocals audio\n",
    "        audio_path = os.path.join(path_vocals, f\"{id}.wav\")\n",
    "        audio, sr = librosa.load(audio_path, sr=TARGET_SR)\n",
    "        # Get annotations\n",
    "        entry = dali_data[id]\n",
    "        anno = entry.annotations['annot']\n",
    "        lines = anno['lines']\n",
    "        # Process each line\n",
    "        for seg_idx, line in enumerate(lines):\n",
    "            # Extract segment\n",
    "            segment_time = line['time']\n",
    "            extract_audio_segment(\n",
    "                audio,\n",
    "                segment_time,\n",
    "                save_path=os.path.join(path_segments, get_segment_fname(id, seg_idx))\n",
    "            )\n",
    "            # Add annotation to dataset\n",
    "            data_list.append((id, seg_idx, line['text']))\n",
    "        \n",
    "    df = pd.DataFrame(data_list, columns=['id', 'segment_index', 'text'])\n",
    "    return df\n",
    "\n",
    "df = make_dataset()\n",
    "df.to_csv(csv_path, index=False)\n",
    "df.head(3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make training dataset & data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "allowed_chars = set('abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ \\'')\n",
    "\n",
    "def clean_lyrics(lyrics: str) -> str:\n",
    "    # Find all numbers in the text using regular expression\n",
    "    num_regex = r'\\d+'\n",
    "    numbers = re.findall(num_regex, lyrics)\n",
    "    \n",
    "    # Convert each number to its word form\n",
    "    for num in numbers:\n",
    "        word_form = num2words(int(num))\n",
    "        lyrics = lyrics.replace(num, word_form)\n",
    "\n",
    "    cleaned = \"\"\n",
    "    for char in lyrics:\n",
    "        if char in allowed_chars:\n",
    "            cleaned += char\n",
    "        elif char == '-':\n",
    "            cleaned += ' '\n",
    "    return cleaned\n",
    "\n",
    "dataset_csv_path = \"dataset.csv\"\n",
    "def transform_dataset(csv_path, path_segments, lang='english'):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df['path'] = df.agg(lambda x: f\"{path_segments}/{x['id']}_{str(x['segment_index'])}.wav\", axis=1)\n",
    "    delete_idx = []\n",
    "    for idx, row in tqdm(df.iterrows()):\n",
    "        song_id = row['id']\n",
    "        # Get annotations\n",
    "        entry = dali_data[song_id]\n",
    "        meta = entry.info['metadata']\n",
    "        song_lang = meta['language']\n",
    "        # Skip different lang\n",
    "        if song_lang != lang:\n",
    "            delete_idx.append(idx)\n",
    "            continue\n",
    "        # Clean invalid data\n",
    "        if not isinstance(row['text'], str) or len(row['text']) == 0:\n",
    "            delete_idx.append(idx)\n",
    "            continue\n",
    "        # Check for audio validity\n",
    "        y, sr = librosa.load(row['path'], sr=TARGET_SR)\n",
    "        yt, _ = librosa.effects.trim(y, top_db=30)\n",
    "        duration = librosa.get_duration(y=yt, sr=sr)\n",
    "        if duration > 3.1 or duration < 0.15: # CUDA out of memory\n",
    "            delete_idx.append(idx)\n",
    "            continue        \n",
    "\n",
    "    df = df.drop(delete_idx)\n",
    "    df = df.drop(['id', 'segment_index'], axis=1)\n",
    "\n",
    "    # Text cleaning\n",
    "    df['text'] = df['text'].map(clean_lyrics)\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    df.dropna(inplace=True)\n",
    "    return df\n",
    "\n",
    "df = transform_dataset(csv_path, path_segments)\n",
    "df.to_csv(dataset_csv_path, index=False)\n",
    "df.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Audio, Dataset\n",
    "\n",
    "dataset_csv_path = \"dataset.csv\"\n",
    "dataset = Dataset.from_csv(dataset_csv_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample of dataset loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import random\n",
    "import librosa\n",
    "\n",
    "rand_int = random.randint(0, len(dataset))\n",
    "\n",
    "def audio_processing(fp):\n",
    "    y, sr = librosa.load(fp, sr=TARGET_SR)\n",
    "    return y\n",
    "\n",
    "print(dataset[rand_int][\"text\"])\n",
    "ipd.Audio(data=audio_processing(dataset[rand_int][\"path\"]), autoplay=True, rate=16000)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "chars_to_ignore_regex = '[\\,\\?\\.\\!\\-\\;\\:\\\"]'\n",
    "\n",
    "\n",
    "def remove_special_characters(batch):\n",
    "    batch[\"text\"] = re.sub(chars_to_ignore_regex, '', batch[\"text\"]).lower()\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def make_vocab(dataset):\n",
    "    vocab = set()\n",
    "    for sample in dataset['text']:\n",
    "        for ch in sample:\n",
    "            vocab.add(ch)\n",
    "    vocab_dict = {v: k for k, v in enumerate(sorted(vocab))}\n",
    "    vocab_dict[\"|\"] = vocab_dict[\" \"]\n",
    "    del vocab_dict[\" \"]\n",
    "    vocab_dict[\"[UNK]\"] = len(vocab_dict)\n",
    "    vocab_dict[\"[PAD]\"] = len(vocab_dict)\n",
    "    with open('vocab.json', 'w') as vocab_file:\n",
    "        json.dump(vocab_dict, vocab_file)\n",
    "    return vocab_dict\n",
    "\n",
    "vocab_dict = make_vocab(dataset)\n",
    "with open('vocab.json', 'r') as f:\n",
    "    vocab_dict = json.load(f)\n",
    "\n",
    "\n",
    "print(vocab_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lsync",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
